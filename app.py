import streamlit as st
import spacy
from spacy import displacy
from spacy import displacy
import logging
import re

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- spaCyãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ ---
@st.cache_resource
def load_spacy_model(model_name="en_core_web_sm"):
    """æŒ‡å®šã•ã‚ŒãŸspaCyãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€å­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’è©¦ã¿ã‚‹"""
    try:
        return spacy.load(model_name)
    except OSError:
        st.error(f"SpaCyãƒ¢ãƒ‡ãƒ« '{model_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™...")
        try:
            spacy.cli.download(model_name)
            return spacy.load(model_name)
        except Exception as e:
            st.exception(f"ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.stop()

# --- Mappings for Phrase Structure ---
# These are defined globally to be accessible by the tree formatting function.
POS_MAP = {
    "NOUN": "åè©", "PRON": "ä»£åè©", "VERB": "å‹•è©", "AUX": "åŠ©å‹•è©",
    "ADJ": "å½¢å®¹è©", "ADV": "å‰¯è©", "ADP": "å‰ç½®è©", "DET": "é™å®šè©",
    "PUNCT": "å¥èª­ç‚¹", "PROPN": "å›ºæœ‰åè©", "NUM": "æ•°è©", "CCONJ": "ç­‰ä½æ¥ç¶šè©",
    "SCONJ": "å¾“å±æ¥ç¶šè©", "INTJ": "é–“æŠ•è©", "PART": "å°è©", "SYM": "è¨˜å·",
    "X": "ãã®ä»–",
}
DEP_MAP = {
    "nsubj": "åè©çš„ä¸»èª", "ROOT": "æ–‡ã®ä¸»å‹•è© (æ ¹)", "attr": "è£œèª (åè©çš„)",
    "det": "é™å®šè©", "relcl": "é–¢ä¿‚ç¯€", "dobj": "ç›´æ¥ç›®çš„èª",
    "npadvmod": "åè©å¥å‰¯è©ä¿®é£¾èª", "punct": "å¥èª­ç‚¹", "aux": "åŠ©å‹•è©",
    "auxpass": "å—å‹•æ…‹åŠ©å‹•è©", "acomp": "è£œèª (å½¢å®¹è©çš„)", "pobj": "å‰ç½®è©ã®ç›®çš„èª",
    "prep": "å‰ç½®è©å¥", "amod": "å½¢å®¹è©ä¿®é£¾èª", "advmod": "å‰¯è©ä¿®é£¾èª",
    "cc": "ç­‰ä½æ¥ç¶šè©", "conj": "æ¥ç¶šã•ã‚ŒãŸè¦ç´ ", "compound": "è¤‡åˆèª",
    "xcomp": "è£œèª (å‹•è©çš„)", "csubj": "ç¯€ä¸»èª",
    "appos": "åŒæ ¼", "acl": "å½¢å®¹è©å¥", "advcl": "å‰¯è©ç¯€", "agent": "å‹•ä½œä¸»",
    "case": "æ ¼", "ccomp": "è£œæ–‡", "dative": "ä¸æ ¼",
    "expl": "å½¢å¼ä¸»èª/ç›®çš„èª", "mark": "æ¨™è­˜èª", "nummod": "æ•°è©ä¿®é£¾èª",
    "oprd": "ç›®çš„æ ¼è£œèª", "parataxis": "ä¸¦åˆ—é–¢ä¿‚", "poss": "æ‰€æœ‰æ ¼",
    "preconj": "å‰ç½®æ¥ç¶šè©", "predet": "å‰é™å®šè©", "quantmod": "æ•°é‡ä¿®é£¾èª",
}
RELATION_TEMPLATES = {
    "nsubj": "{}ã¯{}ã®ä¸»èªã§ã™ã€‚",
    "dobj": "{}ã¯{}ã®ç›´æ¥ç›®çš„èªã§ã™ã€‚",
    "iobj": "{}ã¯{}ã®é–“æ¥ç›®çš„èªã§ã™ã€‚",
    "attr": "{}ã¯{}ã®è£œèªã§ã™ã€‚",
    "acomp": "{}ã¯{}ã®è£œèªã§ã™ã€‚",
    "det": "{}ã¯{}ã‚’é™å®šã—ã¦ã„ã¾ã™ã€‚",
    "amod": "{}ã¯{}ã‚’ä¿®é£¾ã—ã¦ã„ã¾ã™ã€‚",
    "advmod": "{}ã¯{}ã‚’ä¿®é£¾ã—ã¦ã„ã¾ã™ã€‚",
    "prep": "{}ã¯{}ã®å‰ç½®è©å¥ã®å§‹ã¾ã‚Šã§ã™ã€‚",
    "pobj": "{}ã¯{}ã®å‰ç½®è©ã®ç›®çš„èªã§ã™ã€‚",
    "aux": "{}ã¯{}ã®åŠ©å‹•è©ã§ã™ã€‚",
    "auxpass": "{}ã¯{}ã®å—å‹•æ…‹åŠ©å‹•è©ã§ã™ã€‚",
    "relcl": "{}ã¯{}ã‚’èª¬æ˜ã™ã‚‹é–¢ä¿‚ç¯€ã§ã™ã€‚",
    "compound": "{}ã¯{}ã¨è¤‡åˆèªã‚’å½¢æˆã—ã¦ã„ã¾ã™ã€‚",
    "cc": "{}ã¯{}ã¨{}ã‚’æ¥ç¶šã—ã¦ã„ã¾ã™ã€‚",
    "conj": "{}ã¯{}ã¨æ¥ç¶šã•ã‚Œã¦ã„ã¾ã™ã€‚",
    "default": "{}ã¯{}ã«ä¾å­˜ã—ã¦ã„ã¾ã™ã€‚",
}

def get_tree_style_css():
    """CSS for the phrase structure tree."""
    return """
    <style>
        .tree ul {
            position: relative;
            padding: 0 0 0 20px;
            margin: 0;
            list-style: none;
        }
        .tree li {
            position: relative;
            padding: 3px 0 3px 20px;
            line-height: 1.5;
        }
        .tree li::before, .tree li::after {
            content: '';
            position: absolute;
            left: 0;
        }
        .tree li::before {
            border-left: 1px solid #999;
            height: 100%;
            width: 1px;
            top: -12px;
        }
        .tree li:last-child::before {
            height: 28px;
        }
        .tree li::after {
            border-top: 1px solid #999;
            height: 1px;
            width: 20px;
            top: 16px;
        }
        .tree .token-info {
            display: inline-block;
            padding: 3px 8px;
            border-radius: 5px;
            margin-bottom: 3px;
            border: 1px solid #ccc;
            background-color: #e8dff5; /* Light purple */
        }
        .tree .head {
            background-color: #e8dff5; /* Light purple */
        }
        .tree .modifier {
            background-color: #f5f5f5; /* Lighter grey */
        }
        .tree .pos-dep {
            font-size: 0.85em;
            color: #555;
        }
        .tree .relation {
            font-size: 0.9em;
            color: #007bff; /* Blue */
            margin-left: 15px;
        }
    </style>
    """

def generate_phrase_tree_html(token, elements, main_verb, level=0):
    """
    Generates an HTML tree structure for a token and its children.
    When rendering the verb phrase, the subject is omitted.
    """
    html_parts = []
    pos_jp = POS_MAP.get(token.pos_, token.pos_)
    dep_jp = DEP_MAP.get(token.dep_, token.dep_)
    token_class = "head" if level == 0 else "modifier"

    html_parts.append("<li>")
    html_parts.append(f"<div class='token-info {token_class}'>")
    html_parts.append(f"<strong>{token.text}</strong> <span class='pos-dep'>({pos_jp} / {dep_jp})</span>")

    # Add relationship explanation
    relation_explanation = ""
    if level == 0 and token != main_verb:
        template = RELATION_TEMPLATES.get(token.dep_, RELATION_TEMPLATES["default"])
        try:
            relation_explanation = template.format(token.text, main_verb.text)
        except IndexError:
            relation_explanation = f"{token.text}ã¯{main_verb.text}ã«ä¾å­˜ã—ã¦ã„ã¾ã™ã€‚"
    elif level > 0:
        template = RELATION_TEMPLATES.get(token.dep_, RELATION_TEMPLATES["default"])
        try:
            relation_explanation = template.format(token.text, token.head.text)
        except IndexError:
            relation_explanation = f"{token.text}ã¯{token.head.text}ã«ä¾å­˜ã—ã¦ã„ã¾ã™ã€‚"
    
    if relation_explanation:
        html_parts.append(f"<span class='relation'>&mdash; {relation_explanation}</span>")

    html_parts.append("</div>")

    # Process children
    children = list(token.children)
    if children:
        html_parts.append("<ul>")
        for child in children:
            # When rendering the main verb's tree (verb phrase), skip the subject.
            if token == main_verb and child == elements.get("subject"):
                continue
            
            html_parts.append(generate_phrase_tree_html(child, elements, main_verb, level + 1))
        html_parts.append("</ul>")

    html_parts.append("</li>")
    return "".join(html_parts)

# --- spaCyãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ ---
@st.cache_resource
def load_spacy_model(model_name="en_core_web_sm"):
    """æŒ‡å®šã•ã‚ŒãŸspaCyãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€å­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’è©¦ã¿ã‚‹"""
    try:
        return spacy.load(model_name)
    except OSError:
        st.error(f"SpaCyãƒ¢ãƒ‡ãƒ« '{model_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™...")
        try:
            spacy.cli.download(model_name)
            return spacy.load(model_name)
        except Exception as e:
            st.exception(f"ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.stop()

nlp = load_spacy_model()
st.markdown(get_tree_style_css(), unsafe_allow_html=True)

# --- è§£æé–¢æ•° ---
def find_sentence_elements(doc):
    """
    spaCyã®Docã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰æ–‡ã®ä¸»è¦ãªè¦ç´ ã‚’ç‰¹å®šã—ã€æ–‡å‹ã¨æ…‹ã‚’åˆ¤å®šã™ã‚‹ï¼ˆä¿®æ­£ç‰ˆï¼‰ã€‚
    """
    elements = {"subject": None, "verb": None, "dobj": None, "iobj": None, "complement": None, "agent": None, "voice": "èƒ½å‹•æ…‹"}
    pattern = "ä¸æ˜"
    
    passive_verb = None
    passive_aux = None

    # 1. ã¾ãšã€æ–‡å…¨ä½“ã§å—å‹•æ…‹ã®æ§‹é€ ï¼ˆauxpassï¼‰ãŒå­˜åœ¨ã™ã‚‹ã‹ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã™ã‚‹
    for token in doc:
        if token.dep_ == "auxpass":
            passive_aux = token
            passive_verb = token.head
            break # å—å‹•æ…‹ã®æ ¸å¿ƒéƒ¨åˆ†ã‚’è¦‹ã¤ã‘ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹

    if passive_verb and passive_aux:
        # --- å—å‹•æ…‹ã®å‡¦ç† ---
        elements["voice"] = "å—å‹•æ…‹"
        elements["verb"] = passive_verb
        
        # å—å‹•æ…‹ã®ä¸»èª (nsubjpass) ã‚’æ¢ã™
        for child in passive_verb.children:
            if child.dep_ == "nsubjpass":
                elements["subject"] = child
                break
        
        # å‹•ä½œä¸» (agent) ã‚’æ¢ã™
        for child in passive_verb.children:
            if child.dep_ == "agent":
                # agentã®å­ã‹ã‚‰å®Ÿéš›ã®å‹•ä½œä¸»ï¼ˆåè©ï¼‰ã‚’å–å¾—
                for grand_child in child.children:
                    if grand_child.dep_ == "pobj":
                        elements["agent"] = grand_child
                        break
                break
        
        # å—å‹•æ…‹ã®æ–‡ã§ã¯ã€è£œèªã¯å­˜åœ¨ã—ã†ã‚‹ (ä¾‹: The room was painted blue.)
        for child in passive_verb.children:
            if child.dep_ in ["attr", "acomp", "oprd"]:
                elements["complement"] = child
                break
        
        # å—å‹•æ…‹ã®æ–‡å‹ã¯é€šå¸¸ã€èƒ½å‹•æ…‹ã®æ–‡å‹ã«åŸºã¥ã„ã¦åˆ¤æ–­ã•ã‚Œã‚‹ãŸã‚ã€ã“ã“ã§ã¯ç‰¹å®šã®æ–‡å‹åã¯ä»˜ã‘ãªã„
        pattern = "å—å‹•æ…‹ã®æ–‡"

    else:
        # --- èƒ½å‹•æ…‹ã®å‡¦ç† ---
        elements["voice"] = "èƒ½å‹•æ…‹"
        main_verb = None
        for token in doc:
            if token.dep_ == "ROOT" and token.pos_ in ["VERB", "AUX"]:
                main_verb = token
                break
        
        if main_verb:
            elements["verb"] = main_verb
            
            # èƒ½å‹•æ…‹ã®ä¸»èª (nsubj) ã‚’æ¢ã™
            for child in main_verb.children:
                if child.dep_ == "nsubj":
                    elements["subject"] = child
                    break
            
            # ç›®çš„èªã¨è£œèªã‚’æ¢ã™
            for child in main_verb.children:
                if child.dep_ == "dobj":
                    elements["dobj"] = child
                if child.dep_ in ["iobj", "dative"]:
                    elements["iobj"] = child
                if child.dep_ in ["attr", "acomp", "oprd"]:
                    elements["complement"] = child

            # æ–‡å‹åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
            s = elements["subject"]
            v = elements["verb"]
            o1 = elements["dobj"]
            o2 = elements["iobj"]
            c = elements["complement"]

            if s and v:
                if o1 and c and c.dep_ == "oprd": # SVOC (ç›®çš„æ ¼è£œèª)
                     pattern = "SVOC (ç¬¬5æ–‡å‹)"
                elif o1 and o2:
                     pattern = "SVOO (ç¬¬4æ–‡å‹)"
                elif o1:
                     pattern = "SVO (ç¬¬3æ–‡å‹)"
                elif c:
                     pattern = "SVC (ç¬¬2æ–‡å‹)"
                else:
                     pattern = "SV (ç¬¬1æ–‡å‹)"

    elements["pattern_name"] = pattern
    return pattern, elements

def find_clause_elements(doc):
    """
    spaCyã®Docã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰ä¸»ç¯€ã¨å¾“å±ç¯€ã‚’ç‰¹å®šã—ã€ãã‚Œãã‚Œã®è¦ç´ ã‚’æŠ½å‡ºã™ã‚‹ã€‚
    """
    clauses = []
    
    # ä¸»ç¯€ã®å‹•è©ï¼ˆROOTï¼‰ã‚’è¦‹ã¤ã‘ã‚‹
    main_verbs = [token for token in doc if token.dep_ == "ROOT" and token.pos_ in ["VERB", "AUX"]]
    
    # ç­‰ä½æ¥ç¶šè©ã§çµã°ã‚ŒãŸè¤‡æ•°ã®ä¸»ç¯€å‹•è©ã‚’å‡¦ç†
    for verb in main_verbs:
        # ä¸»ç¯€ã®ä¸»èªã‚’è¦‹ã¤ã‘ã‚‹
        subject = next((child for child in verb.children if child.dep_ in ["nsubj", "nsubjpass"]), None)
        
        # ä¸»ç¯€ã®ç¯„å›²ã‚’æ±ºå®šï¼ˆå˜ç´”åŒ–ã®ãŸã‚ã€å‹•è©ã®ã‚µãƒ–ãƒ„ãƒªãƒ¼å…¨ä½“ã‚’ä¸»ç¯€ã¨è¦‹ãªã™ï¼‰
        main_clause_span = doc[min(t.i for t in verb.subtree) : max(t.i for t in verb.subtree) + 1]

        clauses.append({
            "type": "ä¸»ç¯€",
            "verb": verb,
            "subject": subject,
            "introducer": None,
            "span": main_clause_span
        })

        # ä¸»ç¯€ã«æ¥ç¶šã•ã‚ŒãŸä»–ã®ç¯€ï¼ˆconjï¼‰ã‚‚ä¸»ç¯€ã¨ã—ã¦æ‰±ã†
        for conjunct_verb in verb.conjuncts:
             conjunct_subject = next((child for child in conjunct_verb.children if child.dep_ in ["nsubj", "nsubjpass"]), None)
             if conjunct_subject:
                    conjunct_clause_span = doc[min(t.i for t in conjunct_verb.subtree) : max(t.i for t in conjunct_verb.subtree) + 1]
                    clauses.append({
                        "type": "ä¸»ç¯€", # ç­‰ä½æ¥ç¶šè©ã§çµã°ã‚Œã¦ã„ã‚‹ãŸã‚ä¸»ç¯€
                        "verb": conjunct_verb,
                        "subject": conjunct_subject,
                        "introducer": next((child for child in conjunct_verb.children if child.dep_ == "cc"), None),
                        "span": conjunct_clause_span
                    })


    # å¾“å±ç¯€ã‚’è¦‹ã¤ã‘ã‚‹ (advcl, relcl, ccomp)
    for token in doc:
        # å‰¯è©ç¯€ (advcl)
        if token.dep_ == "advcl":
            sub_verb = token
            sub_subject = next((child for child in sub_verb.children if child.dep_ in ["nsubj", "nsubjpass"]), None)
            introducer = next((child for child in sub_verb.children if child.dep_ == "mark"), None)
            
            if sub_subject:
                sub_clause_span = doc[min(t.i for t in sub_verb.subtree) : max(t.i for t in sub_verb.subtree) + 1]
                clauses.append({
                    "type": "å¾“å±ç¯€",
                    "verb": sub_verb,
                    "subject": sub_subject,
                    "introducer": introducer,
                    "span": sub_clause_span
                })

        # é–¢ä¿‚ç¯€ (relcl)
        elif token.dep_ == "relcl":
            rel_verb = token
            # é–¢ä¿‚ç¯€ã®ä¸»èªã¯ã€é–¢ä¿‚ä»£åè©(who, which)ã‹ã€å…ˆè¡Œè©ã«ä¾å­˜ã™ã‚‹
            rel_subject = next((child for child in rel_verb.children if child.dep_ in ["nsubj", "nsubjpass"]), None)
            # é–¢ä¿‚ä»£åè©ãŒä¸»èªã§ãªã„å ´åˆã€å…ˆè¡Œè©ãŒä¸»èªã¨ãªã‚‹ã“ã¨ãŒã‚ã‚‹
            if not rel_subject:
                 rel_subject = rel_verb.head # å…ˆè¡Œè©
            
            if rel_subject:
                rel_clause_span = doc[min(t.i for t in rel_verb.subtree) : max(t.i for t in rel_verb.subtree) + 1]

                # é–¢ä¿‚ä»£åè©ãŒå°å…¥èª
                # ç¯€ã®é–‹å§‹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å°å…¥èªå€™è£œã¨ã™ã‚‹
                introducer = None
                if rel_clause_span and rel_clause_span[0].pos_ in ["SCONJ", "PRON", "ADP"]:
                    introducer = rel_clause_span[0]

                clauses.append({
                    "type": "å¾“å±ç¯€",
                    "verb": rel_verb,
                    "subject": rel_subject,
                    "introducer": introducer,
                    "span": rel_clause_span
                })
        
        # è£œæ–‡ç¯€ (ccomp)
        elif token.dep_ == "ccomp":
            ccomp_verb = token
            ccomp_subject = next((child for child in ccomp_verb.children if child.dep_ in ["nsubj", "nsubjpass"]), None)
            introducer = next((child for child in ccomp_verb.children if child.dep_ == "mark"), None)

            if ccomp_subject:
                ccomp_clause_span = doc[min(t.i for t in ccomp_verb.subtree) : max(t.i for t in ccomp_verb.subtree) + 1]
                clauses.append({
                    "type": "å¾“å±ç¯€",
                    "verb": ccomp_verb,
                    "subject": ccomp_subject,
                    "introducer": introducer,
                    "span": ccomp_clause_span
                })


    # ç¯€ã‚’æ–‡ä¸­ã®å‡ºç¾é †ã«ã‚½ãƒ¼ãƒˆ
    clauses.sort(key=lambda c: c["span"].start)
    
    return clauses

def render_highlighted_text(doc, elements):
    """
    æ–‡ã®å„è¦ç´ ï¼ˆä¸»èªã€å‹•è©ã€ç›®çš„èªã€è£œèªï¼‰ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¦HTMLæ–‡å­—åˆ—ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    å‡¡ä¾‹ã®è‰²ã¨ä¸€è‡´ã•ã›ã‚‹ã€‚æ–‡å‹æ§‹æˆè¦ç´ ã®è¡¨ç¤ºã‚‚å«ã‚€ã€‚
    """
    highlighted_parts = []
    element_map = {
        elements["subject"]: ("ä¸»èª", "#ADD8E6", "S"),
        elements["verb"]: ("å‹•è©", "#FFB6C1", "V"),
        elements["dobj"]: ("ç›®çš„èª", "#FFDAB9", "O"),
        elements["iobj"]: ("é–“æ¥ç›®çš„èª", "#90EE90", "O"),
        elements["complement"]: ("è£œèª", "#D8BFD8", "C"),
    }

    for token in doc:
        token_html = token.text
        for element, (label, color, abbr) in element_map.items():
            if element and token.idx == element.idx:
                token_html = f'<span style="background-color: {color}; font-weight: bold; padding: 2px 5px; border-radius: 5px;" title="{label}">{token.text}</span>'
                break
        
        highlighted_parts.append(token_html)
        if token.whitespace_:
            highlighted_parts.append(token.whitespace_)
        elif token.i < len(doc) - 1 and not doc[token.i+1].is_punct:
            highlighted_parts.append(" ")
            
    return "".join(highlighted_parts)

def render_clause_highlighted_text(doc, clauses):
    """
    æ–‡ã®å„ç¯€ã‚’èƒŒæ™¯è‰²ã¨ã‚­ãƒ¼è¦ç´ ã®ã‚¢ãƒ³ãƒ€ãƒ¼ãƒ©ã‚¤ãƒ³ã§ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¦HTMLæ–‡å­—åˆ—ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    highlighted_html_parts = []
    clause_summaries = []

    token_highlight_info = {}

    for clause in clauses:
        clause_type = clause["type"]
        # Background colors for clauses
        bg_color = '#E0FFFF' if clause_type == 'ä¸»ç¯€' else '#FFFACD' # Light Cyan for main, Lemon Chiffon for subordinate
        # Underline colors for key elements
        underline_color = "blue" if clause_type == "ä¸»ç¯€" else "#DC143C" # Blue for main, Crimson for subordinate
        
        # Generate summary for each clause
        clause_summaries.append(f"<span style=\"background-color: {bg_color}; padding: 2px 5px; border-radius: 3px; font-size: 1.2em;\">{clause_type}</span>")
        
        # Populate token_highlight_info for background colors
        for token_in_span in clause["span"]:
            # If a token belongs to multiple clauses, the last one processed (which should be the most specific/inner clause) will set its background.
            token_highlight_info[token_in_span] = token_highlight_info.get(token_in_span, {})
            token_highlight_info[token_in_span]['bg_color'] = bg_color

        # Populate token_highlight_info for key elements (subject, verb, introducer)
        key_elements_map = {
            clause["subject"]: "ä¸»èª",
            clause["verb"]: "å‹•è©",
        }
        if clause["introducer"]:
            key_elements_map[clause["introducer"]] = "å°å…¥èª"

        for key_elem, role in key_elements_map.items():
            if key_elem:
                token_highlight_info[key_elem] = token_highlight_info.get(key_elem, {})
                token_highlight_info[key_elem]['underline'] = True
                token_highlight_info[key_elem]['underline_color'] = underline_color
                token_highlight_info[key_elem]['roles'] = token_highlight_info[key_elem].get('roles', [])
                if role not in token_highlight_info[key_elem]['roles']:
                    token_highlight_info[key_elem]['roles'].append(role)

    # Now, iterate through the doc and build the HTML
    for token in doc:
        styles = []
        title_attr = ""
        
        info = token_highlight_info.get(token, {})

        if 'bg_color' in info:
            styles.append(f"background-color: {info['bg_color']}")
        
        if info.get('underline'):
            styles.append(f"text-decoration: underline; text-decoration-color: {info['underline_color']};")
            if info.get('roles'):
                title_attr = f'title="{", ".join(info['roles'])}"'
        
        if styles or title_attr:
            token_html = f'<span {title_attr} style="{"; ".join(styles)}">{token.text}</span>'
        else:
            token_html = token.text
        
        highlighted_html_parts.append(token_html)
        
        # Handle whitespace
        if token.whitespace_:
            highlighted_html_parts.append(token.whitespace_)
        elif token.i < len(doc) - 1 and not doc[token.i+1].is_punct:
            highlighted_html_parts.append(" ")
            
    return "".join(highlighted_html_parts), clause_summaries

# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æœ¬ä½“ ---
st.title("è‹±æ–‡æ§‹é€ è§£æã‚¢ãƒ—ãƒª")

# --- çŠ¶æ…‹ç®¡ç†ã¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ ---
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’åˆæœŸåŒ–
if "user_input" not in st.session_state:
    st.session_state.user_input = "She is a very famous singer."

# selectboxã®å€¤ãŒå¤‰æ›´ã•ã‚ŒãŸã¨ãã«å‘¼ã³å‡ºã•ã‚Œã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
def update_text_from_sample():
    st.session_state.user_input = st.session_state.sample_select

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
st.sidebar.header("ä¾‹æ–‡")
sample_sentences = [
    "The birds are flying in the sky.", # SV (ç¬¬1æ–‡å‹)
    "She is a very famous singer.", # SVC (ç¬¬2æ–‡å‹)
    "The man sitting by the window is my father.", # SVC (ç¬¬2æ–‡å‹)
    "My friend plays the piano.", # SVO (ç¬¬3æ–‡å‹)
    "He gave me a beautiful present.", # SVOO (ç¬¬4æ–‡å‹)
    "I like apples and he loves oranges.",
    "This is the book that I bought yesterday.",
    "The ball was kicked by the boy.",
    "English is spoken all over the world.",
    "The window was broken.",
]
st.sidebar.selectbox(
    "è©¦ã—ãŸã„ä¾‹æ–‡ã‚’é¸ã‚“ã§ãã ã•ã„:",
    [""] + sample_sentences,
    key="sample_select",
    on_change=update_text_from_sample
)

st.sidebar.markdown("### æ–‡å‹åˆ¤åˆ¥ã®è‰²åˆ†ã‘")
st.sidebar.markdown("<span style=\"background-color: #ADD8E6; padding: 2px 5px; border-radius: 3px;\">ä¸»èª (S)</span>", unsafe_allow_html=True)
st.sidebar.markdown("<span style=\"background-color: #FFB6C1; padding: 2px 5px; border-radius: 3px;\">å‹•è© (V)</span>", unsafe_allow_html=True)
st.sidebar.markdown("<span style=\"background-color: #FFDAB9; padding: 2px 5px; border-radius: 3px;\">ç›®çš„èª (O)</span>", unsafe_allow_html=True)
st.sidebar.markdown("<span style=\"background-color: #90EE90; padding: 2px 5px; border-radius: 3px;\">é–“æ¥ç›®çš„èª (O)</span>", unsafe_allow_html=True)
st.sidebar.markdown("<span style=\"background-color: #D8BFD8; padding: 2px 5px; border-radius: 3px;\">è£œèª (C)</span>", unsafe_allow_html=True)

st.sidebar.markdown("### æ–‡ç¯€ã®è‰²åˆ†ã‘")
st.sidebar.markdown("<span style=\"background-color: #E0FFFF; padding: 2px 5px; border-radius: 3px;\">ä¸»ç¯€</span>", unsafe_allow_html=True)
st.sidebar.markdown("<span style=\"background-color: #FFFACD; padding: 2px 5px; border-radius: 3px;\">å¾“å±ç¯€</span>", unsafe_allow_html=True)

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
user_input = st.text_area("è§£æã—ãŸã„è‹±æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", key="user_input")

if st.button("è§£æã™ã‚‹"):
    
    if user_input:
        doc = nlp(user_input)
        pattern, elements = find_sentence_elements(doc)
        
        st.header("è§£æçµæœ")
        
        if elements["subject"] and elements["verb"]:
            st.success(f"æ–‡å‹ã‚’ç‰¹å®šã—ã¾ã—ãŸï¼")

            # --- ã‚¿ãƒ–å½¢å¼ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
            tab1, tab2, tab3, tab4, tab5 = st.tabs([
                "æ–‡ã®éª¨æ ¼ï¼ˆæ–‡å‹ï¼‰", 
                "å¥ã®åˆ†è§£", 
                "ç¯€ã®æ§‹é€ ", 
                "å˜èªã®é–¢ä¿‚ï¼ˆè©³ç´°ï¼‰",
                "å®Ÿè·µã¨å¿œç”¨ï¼ˆæ…‹ï¼‰"
            ])

            with tab1:
                st.header("æ–‡å‹ã¨ä¸»è¦ç´ ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ")
                st.markdown("æ–‡ã®éª¨æ ¼ã‚’æ´ã‚€ãŸã‚ã«ã€æ–‡ã®ä¸»è¦ãªè¦ç´ ï¼ˆä¸»èªã€å‹•è©ã€ç›®çš„èªã€è£œèªï¼‰ã¨ã€ãã‚ŒãŒæ§‹æˆã™ã‚‹ã€Œæ–‡å‹ã€ã‚’ç¢ºèªã—ã¾ã™ã€‚")
                st.info(f"ä¾‹æ–‡: {doc.text}")
                st.markdown(f"### <span style=\"font-size: 1.2em;\">æ–‡å‹ã®åˆ¤åˆ¥: **{elements['pattern_name']}**</span>", unsafe_allow_html=True)
                
                # --- ææ¡ˆ1: ä¸€è¨€ã‚µãƒãƒªãƒ¼è§£èª¬ã®è¿½åŠ  ---
                pattern_summary = {
                    "SV (ç¬¬1æ–‡å‹)": "ğŸ’¡ **ã“ã‚Œã¯ã€ŒSãŒVã™ã‚‹ã€ã¨ã„ã†ã€åŸºæœ¬çš„ãªå‹•ä½œã‚’è¡¨ã™æ–‡ã®å½¢ã§ã™ã€‚**",
                    "SVC (ç¬¬2æ–‡å‹)": "ğŸ’¡ **ã“ã‚Œã¯ã€ŒSã¯Cã§ã‚ã‚‹ã€ã¨ã€ä¸»èªã®çŠ¶æ…‹ã‚„æ€§è³ªã‚’èª¬æ˜ã™ã‚‹æ–‡ã®å½¢ã§ã™ã€‚**",
                    "SVO (ç¬¬3æ–‡å‹)": "ğŸ’¡ **ã“ã‚Œã¯ã€ŒSãŒOã‚’Vã™ã‚‹ã€ã¨ã€ä¸»èªã®å‹•ä½œãŒå¯¾è±¡ï¼ˆç›®çš„èªï¼‰ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹æ–‡ã®å½¢ã§ã™ã€‚**",
                    "SVOO (ç¬¬4æ–‡å‹)": "ğŸ’¡ **ã“ã‚Œã¯ã€ŒSãŒO1ã«O2ã‚’Vã™ã‚‹ã€ã¨ã€èª°ã‹ã«ä½•ã‹ã‚’ä¸ãˆã‚‹ãƒ»å—ã‘å–ã‚‹å‹•ä½œã‚’è¡¨ã™æ–‡ã®å½¢ã§ã™ã€‚**",
                }.get(elements["pattern_name"], "")
                if pattern_summary:
                    st.markdown(f"<p>{pattern_summary}</p>", unsafe_allow_html=True)

                # --- ææ¡ˆ3: æ–‡å‹æ§‹æˆè¦ç´ ã®æ–‡å­—åˆ—ã‚’è‰²ä»˜ãã§ç”Ÿæˆ ---
                display_elements = []
                if elements["subject"]: display_elements.append((elements["subject"].i, f"<span style=\"background-color: #ADD8E6; padding: 2px 5px; border-radius: 3px;\">ä¸»èª (S)</span>"))
                if elements["verb"]: display_elements.append((elements["verb"].i, f"<span style=\"background-color: #FFB6C1; padding: 2px 5px; border-radius: 3px;\">å‹•è© (V)</span>"))
                if elements["dobj"]: display_elements.append((elements["dobj"].i, f"<span style=\"background-color: #FFDAB9; padding: 2px 5px; border-radius: 3px;\">ç›®çš„èª (O)</span>"))
                if elements["iobj"]: display_elements.append((elements["iobj"].i, f"<span style=\"background-color: #90EE90; padding: 2px 5px; border-radius: 3px;\">é–“æ¥ç›®çš„èª (O)</span>"))
                if elements["complement"]: display_elements.append((elements["complement"].i, f"<span style=\"background-color: #D8BFD8; padding: 2px 5px; border-radius: 3px;\">è£œèª (C)</span>"))

                # token.i (ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹) ã§ã‚½ãƒ¼ãƒˆ
                display_elements.sort(key=lambda x: x[0])

                # ã‚½ãƒ¼ãƒˆã•ã‚ŒãŸHTMLæ–‡å­—åˆ—ã‚’çµåˆ
                pattern_elements_html_list = [item[1] for item in display_elements]
                pattern_info_html = f"<p><b>{elements['pattern_name']}</b>: {' '.join(pattern_elements_html_list)}</p>"
                st.markdown(pattern_info_html, unsafe_allow_html=True)

                highlighted_sentence_html = render_highlighted_text(doc, elements)
                st.markdown(highlighted_sentence_html, unsafe_allow_html=True)

            with tab2:
                st.header("å¥ã®æ§‹é€ åˆ†è§£")
                st.markdown("ä¸»èªã‚„å‹•è©ãŒã©ã®ã‚ˆã†ãªå˜èªã®é›†ã¾ã‚Šã§ã§ãã¦ã„ã‚‹ã‹ã€ãã®å†…éƒ¨æ§‹é€ ã‚’è©³ã—ãè¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
                st.info(f"ä¾‹æ–‡: {doc.text}")
                if elements["subject"]:
                    st.markdown("#### ä¸»èªã®æ§‹é€ :")
                    subject_root = elements["subject"]
                    subject_tree_html = generate_phrase_tree_html(subject_root, elements, elements["verb"])
                    st.markdown(f"<ul>{subject_tree_html}</ul>", unsafe_allow_html=True)
                else:
                    st.info("ä¸»èªã®æ§‹é€ ã‚’è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

                if elements["verb"]:
                    st.markdown("#### å‹•è©å¥ã®æ§‹é€ :")
                    verb_root = elements["verb"]
                    verb_tree_html = generate_phrase_tree_html(verb_root, elements, elements["verb"])
                    st.markdown(f"<ul>{verb_tree_html}</ul>", unsafe_allow_html=True)

            with tab3:
                st.header("ç¯€ã®æ§‹é€ ")
                clauses = find_clause_elements(doc)
                if clauses:
                    st.markdown("ã“ã®æ–‡ãŒæ¥ç¶šè©ãªã©ã§ã©ã†åŒºåˆ‡ã‚‰ã‚Œã€è¤‡æ•°ã®ã€ŒãƒŸãƒ‹æ–‡ã€ã§æ§‹æˆã•ã‚Œã¦ã„ã‚‹ã‹ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
                    st.info(f"ä¾‹æ–‡: {doc.text}")
                    st.markdown("**æ–‡ç¯€ã®è‰²åˆ†ã‘ï¼ˆèƒŒæ™¯è‰²ã¨ã‚¢ãƒ³ãƒ€ãƒ¼ãƒ©ã‚¤ãƒ³ï¼‰:** ã™ã¹ã¦ã®ç¯€ï¼ˆä¸»ç¯€ãƒ»å¾“å±ç¯€ï¼‰ã®ç¯„å›²ã‚’èƒŒæ™¯è‰²ã§åŒºåˆ¥ã—ã€å„ç¯€ã®ä¸»èªãƒ»å‹•è©ãƒ»å°å…¥èªã«ã‚¢ãƒ³ãƒ€ãƒ¼ãƒ©ã‚¤ãƒ³ã‚’å¼•ãã¾ã™ã€‚")
                    highlighted_html, clause_summaries = render_clause_highlighted_text(doc, clauses)
                    if clause_summaries:
                        st.markdown(" ".join(clause_summaries), unsafe_allow_html=True)
                    st.markdown(highlighted_html, unsafe_allow_html=True)
                    st.markdown("--- å„ç¯€ã®è©³ç´° ---")
                    for i, clause in enumerate(clauses):
                        st.markdown(f"**ç¯€ {i+1} ({clause['type']}):**")
                        if clause.get('subject'):
                            st.markdown(f"- ä¸»èª: {clause['subject'].text}")
                        if clause.get('verb'):
                            st.markdown(f"- å‹•è©: {clause['verb'].text}")
                        if clause.get('introducer'):
                            st.markdown(f"- å°å…¥èª: {clause['introducer'].text}")
                else:
                    st.info("ã“ã®æ–‡ã«ã¯è§£æå¯¾è±¡ã¨ãªã‚‹ç¯€ãŒ1ã¤ã€ã¾ãŸã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

            with tab4:
                st.header("å˜èªã®ä¾å­˜é–¢ä¿‚ï¼ˆè©³ç´°ï¼‰")
                st.markdown("æ–‡ä¸­ã®ã™ã¹ã¦ã®å˜èªé–“ã®æ–‡æ³•çš„ãªé–¢ä¿‚ã‚’è¦–è¦šçš„ã«è¡¨ç¤ºã—ã¾ã™ã€‚çŸ¢å°ã¯å˜èªé–“ã®ä¾å­˜é–¢ä¿‚ã‚’ç¤ºã—ã¾ã™ã€‚")
                
                # --- ææ¡ˆï¼šå›³ã®èª­ã¿æ–¹ã‚¬ã‚¤ãƒ‰ã®è¿½åŠ  ---
                st.markdown("""
                **ã“ã®å›³ã®èª­ã¿æ–¹ã‚¬ã‚¤ãƒ‰**
                - **çŸ¢å°:** å˜èªã¨å˜èªã®æ–‡æ³•çš„ãªç¹‹ãŒã‚Šã‚’è¡¨ã—ã¾ã™ã€‚çŸ¢å°ã®æ ¹å…ƒãŒã€çŸ¢å°ã®å…ˆã®å˜èªã‚’ä¿®é£¾ãƒ»èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚
                - **ãƒ©ãƒ™ãƒ«:** çŸ¢å°ã®ä¸‹ã«ã‚ã‚‹ãƒ©ãƒ™ãƒ«ï¼ˆ`nsubj`ãªã©ï¼‰ã¯ã€ãã®ç¹‹ãŒã‚ŠãŒã©ã®ã‚ˆã†ãªã€Œæ–‡æ³•çš„ãªå½¹å‰²ã€ã‚’æŒã¤ã‹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
                - **ROOT:** ã™ã¹ã¦ã®çŸ¢å°ã‚’è¾¿ã£ã¦ã„ãã¨ã€æ–‡ã®ä¸­å¿ƒã§ã‚ã‚‹**ROOT**ï¼ˆæ ¹ï¼‰ã«è¡Œãç€ãã¾ã™ã€‚
                """)
                st.markdown("---")

                svg = displacy.render(doc, style="dep", options={"compact": True, "distance": 90, "word_spacing": 15, "arrow_spacing": 18})
                
                # --- æ—¥æœ¬èªåŒ–ãƒ­ã‚¸ãƒƒã‚¯ ---
                # ä¾å­˜é–¢ä¿‚ãƒ©ãƒ™ãƒ«ã®æ—¥æœ¬èªåŒ–
                for dep, label_jp in DEP_MAP.items():
                    svg = svg.replace(f'>{dep}</textPath>', f'>{label_jp}</textPath>')
                # å“è©ã‚¿ã‚°ã®æ—¥æœ¬èªåŒ–
                for pos, label_jp in POS_MAP.items():
                    svg = re.sub(rf'<tspan class="displacy-tag" dy="2em" fill="currentColor" x="[0-9.]+">{pos}</tspan>', 
                                 rf'<tspan class="displacy-tag" dy="2em" fill="currentColor" x="[0-9.]+">{label_jp}</tspan>', 
                                 svg)

                # Remove width, height, and style attributes from SVG for responsiveness
                svg = re.sub(r'\s(width|height|style)="[^"]*"', '', svg)
                
                # Wrap the SVG in a scrollable container with fixed height
                st.markdown(f'<div style="max-height: 400px; overflow: auto; border: 1px solid #eee; border-radius: 5px; padding: 10px;">{svg}</div>', unsafe_allow_html=True)

                # --- ææ¡ˆï¼šå‡¡ä¾‹ã®è¿½åŠ  ---
                st.markdown("---")
                st.markdown("**å‡¡ä¾‹ï¼šä¸»ãªä¾å­˜é–¢ä¿‚ãƒ©ãƒ™ãƒ«ã®æ„å‘³**")
                legend_html = "<ul>"
                main_deps = [
                    "nsubj", "ROOT", "dobj", "iobj", "attr", "acomp", 
                    "det", "amod", "advmod", "prep", "pobj", "aux", "relcl", "conj"
                ]
                for dep in main_deps:
                    if dep in DEP_MAP:
                        legend_html += f"<li><b>{dep}:</b> {DEP_MAP[dep]}</li>"
                legend_html += "</ul>"
                st.markdown(legend_html, unsafe_allow_html=True)

            with tab5:
                st.header("å®Ÿè·µã¨å¿œç”¨ - æ–‡æ³•ã¨è¡¨ç¾ã®ã€ä½¿ã„ã“ãªã—ã€ã¸")
                st.markdown("æ–‡ã®æ…‹ï¼ˆèƒ½å‹•æ…‹ãƒ»å—å‹•æ…‹ï¼‰ã‚’ç†è§£ã™ã‚‹ã“ã¨ã¯ã€è¡¨ç¾ã®å¹…ã‚’åºƒã’ã‚‹ç¬¬ä¸€æ­©ã§ã™ã€‚")
                st.info(f"ä¾‹æ–‡: {doc.text}")
                st.markdown(f"### <span style=\"font-size: 1.2em;\">æ–‡ã®æ…‹: **{elements['voice']}**</span>", unsafe_allow_html=True)
                if elements['voice'] == "å—å‹•æ…‹":
                    st.markdown("ğŸ’¡ **è§£èª¬:** ã“ã®æ–‡ã¯å—å‹•æ…‹ã§ã™ã€‚ä¸»èªãŒå‹•ä½œã®ã€å—ã‘æ‰‹ã€ã«ãªã£ã¦ã„ã¾ã™ã€‚")
                    if elements.get('agent'):
                        st.markdown(f"**å‹•ä½œä¸»:** {elements['agent'].text} (byå¥) - ã“ã®å‹•ä½œã‚’è¡Œã£ãŸã®ã¯ {elements['agent'].text} ã§ã™ã­ã€‚")
                    else:
                        st.markdown("**å‹•ä½œä¸»:** ã“ã®æ–‡ã§ã¯å‹•ä½œä¸»ï¼ˆbyå¥ï¼‰ãŒæ˜ç¤ºã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                    st.markdown("**èƒ½å‹•æ…‹ã¸ã®å¤‰æ›ãƒ’ãƒ³ãƒˆ:**")
                    st.markdown("1. å‹•ä½œä¸»ï¼ˆbyå¥ï¼‰ãŒã‚ã‚Œã°ã€ãã‚Œã‚’æ–°ã—ã„ä¸»èªã«ã—ã¾ã™ã€‚ï¼ˆä¾‹: `by the boy` â†’ `The boy`ï¼‰")
                    st.markdown("2. å…ƒã®ä¸»èªã‚’å‹•è©ã®å¾Œã«ç§»å‹•ã•ã›ã¾ã™ã€‚ï¼ˆä¾‹: `The ball` â†’ `... the ball`ï¼‰")
                    st.markdown("3. å‹•è©ã‚’èƒ½å‹•æ…‹ã®å½¢ã«æˆ»ã—ã¾ã™ã€‚ï¼ˆä¾‹: `was kicked` â†’ `kicked`ï¼‰")
                    st.markdown("**ä¾‹:** `The ball was kicked by the boy.` â†’ `The boy kicked the ball.`")
                else:
                    st.markdown("ğŸ’¡ **è§£èª¬:** ã“ã®æ–‡ã¯èƒ½å‹•æ…‹ã§ã™ã€‚ä¸»èªãŒå‹•ä½œã‚’ã€è¡Œã†å´ã€ã«ãªã£ã¦ã„ã¾ã™ã€‚")
                    st.markdown("**å—å‹•æ…‹ã¸ã®å¤‰æ›ãƒ’ãƒ³ãƒˆ:**")
                    st.markdown("1. èƒ½å‹•æ…‹ã®ç›®çš„èªã‚’æ–°ã—ã„ä¸»èªã«ã—ã¾ã™ã€‚ï¼ˆä¾‹: `kicked the ball` â†’ `The ball`ï¼‰")
                    st.markdown("2. å‹•è©ã‚’ `beå‹•è© + éå»åˆ†è©` ã®å½¢ã«ã—ã¾ã™ã€‚ï¼ˆä¾‹: `kicked` â†’ `was kicked`ï¼‰")
                    st.markdown("3. å…ƒã®ä¸»èªã‚’ `by + å‹•ä½œä¸»` ã®å½¢ã§å‹•è©ã®å¾Œã«ç§»å‹•ã•ã›ã¾ã™ã€‚ï¼ˆä¾‹: `The boy` â†’ `by the boy`ï¼‰")
                    st.markdown("**ä¾‹:** `The boy kicked the ball.` â†’ `The boy kicked the ball.`")
            
        else:
            st.warning("ã“ã®æ–‡ã®ä¸»èªã¨å‹•è©ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ãªæ–‡ã§ãŠè©¦ã—ãã ã•ã„ã€‚")
            
    else:
        st.warning("è‹±æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")